# -*- coding: utf-8 -*-
"""hw4_Suyash_Ail.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fplF_WBxl6UKybu6v1fPARlQajTwmaD8
"""

#Importing necessary libraries
import numpy as np
import cv2
import matplotlib.pyplot as plt
import math
from scipy import signal as sig
from scipy import ndimage as nd

def get_input_images(n):
  if n==1:
    image1 = cv2.imread('/content/drive/My Drive/hw4_Task1_Images/pair1/1.JPG')
    image2 = cv2.imread('/content/drive/My Drive/hw4_Task1_Images/pair1/2.JPG')
  if n==2:
    image1 = cv2.imread('/content/drive/My Drive/hw4_Task1_Images/pair2/1.JPG')
    image2 = cv2.imread('/content/drive/My Drive/hw4_Task1_Images/pair2/2.JPG')
  if n==3:
    image1 = cv2.imread('/content/drive/My Drive/hw4_Task1_Images/pair3/1.jpg')
    image2 = cv2.imread('/content/drive/My Drive/hw4_Task1_Images/pair3/2.jpg')
  
  if n==4:
    image1 = cv2.imread('/content/drive/My Drive/hw4_Task1_Images/My_image1/1.jpg')
    image2 = cv2.imread('/content/drive/My Drive/hw4_Task1_Images/My_image1/2.jpg')
  if n==5:
    image1 = cv2.imread('/content/drive/My Drive/hw4_Task1_Images/my_image2/1.jpg')
    image2 = cv2.imread('/content/drive/My Drive/hw4_Task1_Images/my_image2/2.jpg')
  im1=image1.copy()
  im2=image2.copy()
  im1=cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)
  im2=cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY)
  plt.figure(figsize=(10,10))
  plt.imshow(im1,cmap='gray')
  plt.figure(figsize=(10,10))
  plt.imshow(im2,cmap='gray')
  return im1,im2,image1,image2

im1,im2,img1,img2=get_input_images(5)

#define the Harris Detector Function
def Harris_Detector(img_gray,sigma,k=0.04):
    #get the size for haar wavelet
    size_filter=np.ceil(4*sigma)    #take the maximum even number greater than 4sigma
    if size_filter%2!=0:
      size_filter+=1
    else:
      size_filter=size_filter
    size_filter=int(size_filter)

    #get the haar filters
    haar_X=np.ones((size_filter,size_filter))
    haar_X[:,:size_filter//2]*=-1

    haar_Y=np.ones((size_filter,size_filter))
    haar_Y[size_filter//2:,:]*=-1

    #Filter the image using Haar filters. 
    dx = sig.convolve2d(img_gray,haar_X, mode='same', boundary='fill') 
    dy = sig.convolve2d(img_gray,haar_Y, mode='same', boundary='fill') 
    
    

    ###Thanks to Praneet Singh (Also in ECE661) to suggest the idea of using Gaussian Filter
    #get the elements of C matrix
    dx2 = nd.gaussian_filter(np.square(dx),sigma=1)
    dy2 = nd.gaussian_filter(np.square(dy),sigma=1)
    dxy = nd.gaussian_filter(np.multiply(dx,dy),sigma=1)

    
    #Add the points using a summing kernel of size 5*sigma
    ker_width=np.ceil(5*sigma)
    if ker_width %2 ==0:
      ker_width+=1
    ker_width=int(ker_width)
    kernel = np.ones([ker_width, ker_width])
    

    dx2sum=sig.correlate2d(dx2,kernel,mode='same')
    dy2sum=sig.correlate2d(dy2,kernel,mode='same')
    dxdysum=sig.correlate2d(dxy,kernel,mode='same')
    detC = np.subtract(np.multiply(dx2sum,dy2sum),np.multiply(dxdysum,dxdysum))
    trC = np.add(dx2sum,dy2sum)
    
    ##########################################
    #detC = np.multiply(dx2,dy2) - np.square(dxy)
    #trC = np.add(dx2,dy2)
    
    #R = np.divide(detC,np.square(trC))  #doesn't give good results
    #print(R)
    R = np.subtract(detC, k * np.square(trC))  #more stable and accurate mappings
    

##################################################################################
    #Perform Non-Max Supression to remove points that have small R values in a window of m+1,m+1
    win_size = 29 
    win_half = int((win_size - 1)/2) 
    corners=[]
    height,width=img_gray.shape
    #search inside the window the point with the maximum R value and append those points as corner points
    for i in range(win_half, height-win_half-1):
        for j in range(win_half, width-win_half-1):
            R_win= R[i-win_half:i+win_half,j-win_half:j+win_half]
            if R[i,j] == np.max(R_win) and R[i,j] >= 0.1:
                corners.append([i,j])
    return corners

#SSD Measurement Metric to establish correspondence between Interest Points

def SSD_metric(image1,image2,cor1,cor2,ssd_win_size,ratio_global_local_min,thresh_ssd):
    #determine the window size to be used for comparing corner points
    #create the window matrix
    ssd_winh = int((ssd_win_size-1)/2)    
    n1 = len(cor1)    #number of corner points in first image
    n2 = len(cor2)    #number of corner points in second image
    
    matched_pts=[] #initialize a list for matched pairs
    
    #Calculate the SSD matrix for the sets of corners
    SSD_mat = np.zeros((n1,n2))
    
    #get the window pixels surrounding particular corner points
    for i in range(0,n1):
        for j in range(0,n2):
            im1_win = image1[cor1[i,0]-ssd_winh:cor1[i,0]+ssd_winh+1, cor1[i,1]-ssd_winh:cor1[i,1]+ssd_winh+1]
            im2_win = image2[cor2[j,0]-ssd_winh:cor2[j,0]+ssd_winh+1, cor2[j,1]-ssd_winh:cor2[j,1]+ssd_winh+1]
            #find the difference between the pixels values of the two windows
            difference = np.subtract(im1_win,im2_win)
            #find the sum of squared difference
            SSD_mat[i,j] = np.sum(difference**2)
    
    # One corner can be identified to multiple points in the image with the same intensity level. So we threshold the 
    # distance of two pixels to find the best matching pairs.
    #Identify the corresponding corner points in the two images by thresholding 
    for i in range(0,n1):
        for j in range(0,n2):
            #check if the distance is minimum and if the distance is smaller than the mean distance
            if SSD_mat[i,j]==np.min(SSD_mat[i,:]) and SSD_mat[i,j] < thresh_ssd * np.mean(SSD_mat[:,:]):  
                min_local_value = SSD_mat[i,j]  #assign to a temp value
                SSD_mat[i,j] = np.max(SSD_mat[i,:]) #change all other distances along the row to maximum so as to avoid looking into them again.
                
                #compare the local minima with the global minima so as to decide if the rows need to be checked
                if min_local_value / np.min(SSD_mat[:,j]) < ratio_global_local_min:
                    SSD_mat[:,j] = np.max(SSD_mat)
                    SSD_mat[i,j] = min_local_value
                    matched_pts.append([cor1[i,0],cor1[i,1],cor2[j,0],cor2[j,1],SSD_mat[i,j]]) #append distance also for sorting the ones with shortest distance
    #sort the matched points by the minimum distance
    matched_pts.sort(key = lambda x:x[4])
    matched_pts=np.array(matched_pts)[:,:5].astype(int)
    return np.asarray(matched_pts)

#NCC Measurement Metric to establish correspondence between Interest Points
def NCC_metric(image1,image2,cor1,cor2,ncc_win_size,thresh_ncc):
    ncc_winh = int((ncc_win_size-1)/2)
    n1 = len(cor1)
    n2 = len(cor2)
    matched_pts=[] #list of matched points
    
    #Calculate the NCC matrix for the sets of corners
    NCC_mat = np.zeros((n1,n2))
    
    for i in range(0,n1):
        for j in range(0,n2):
            im1_win = image1[cor1[i,0]-ncc_winh:cor1[i,0]+ncc_winh+1, cor1[i,1]-ncc_winh:cor1[i,1]+ncc_winh+1]
            im2_win = image2[cor2[j,0]-ncc_winh:cor2[j,0]+ncc_winh+1, cor2[j,1]-ncc_winh:cor2[j,1]+ncc_winh+1]
            mu1 = np.mean(im1_win) 
            mu2 = np.mean(im2_win)
            num = np.sum(np.multiply(np.subtract(im1_win,mu1),np.subtract(im2_win,mu2)))
            var1 = np.sum(np.square(np.subtract(im1_win,mu1)))
            var2 = np.sum(np.square(np.subtract(im2_win,mu2)))
            denom = np.sqrt(var1*var2)
            NCC_mat[i,j] = num/denom

    for i in range(0,n1):
        for j in range(0,n2):
            if NCC_mat[i,j]==np.max(NCC_mat[i,:]) and NCC_mat[i,j]>thresh_ncc:
                matched_pts.append([cor1[i,0],cor1[i,1],cor2[j,0],cor2[j,1],NCC_mat[i,j]]) #add distance all for sorting for best matches
    matched_pts.sort(key = lambda x:x[4])
    matched_pts=np.array(matched_pts)[:,:5].astype(int)
    return np.asarray(matched_pts)

#Display combined image of the pair of images with interest points and correspondences
def displayImagewithInterestPoints(img1,img2,corners):
    #Get shape of the output image
    nrows = max(img1.shape[0], img2.shape[0])
    ncol = img1.shape[1]+img2.shape[1]
    
    #Initialize combined output image
    out_img = np.zeros((nrows,ncol,3))
    
    #Copy Image 1 to left half of the output image
    out_img[:img1.shape[0], :img1.shape[1]] = img1
    
    #Copy Image 2 to right half of the output image
    out_img[:img2.shape[0], img1.shape[1]:img1.shape[1]+img2.shape[1]] = img2

    for xy in corners[:30]:
        cv2.circle(out_img,(xy[1], xy[0]),4,(0,0,0),2) #interest points from Image 1
        cv2.circle(out_img,(img1.shape[1]+xy[3],xy[2]),4,(0,0,0),2) #Interest points form Image 2
        cv2.line(out_img,(xy[1],xy[0]),(img1.shape[1]+xy[3],xy[2]), (0,255,0)) #Lines joining interest points
    return out_img

sigma_harris = [0.6,1.2,1.6,2.2]
#sigma_harris = [1.4]

for sigma in sigma_harris:
            img1_gray = im1
            img2_gray = im2
            corner_img1 = Harris_Detector(img1_gray,sigma)
            corner_img2 = Harris_Detector(img2_gray,sigma)
            print("Number of Corners Detected in Image 1 = ", len(corner_img1))
            print("Number of Corners Detected in Image 2 = ", len(corner_img2))
            ssd_ratio = 0.85 #ratio of local minima of mathces
            thresh_ssd = 2.5 #threshold for mean
            win_size_ssd = 25 # win_size_ssd x win_size_ssd, window size for examining ssd metric

            corner_img1 = np.array(corner_img1)
            corner_img2 = np.array(corner_img2)
            
            Cord_SSD = SSD_metric(img1_gray,img2_gray,corner_img1,corner_img2,win_size_ssd,ssd_ratio,thresh_ssd)
            out_image_ssd = displayImagewithInterestPoints(img1,img2,Cord_SSD)
            cv2.imwrite('HarrisSSDbalcony'+'_sigma_'+str(sigma)+'.jpg',out_image_ssd)
            
            #For NCC
            thresh_ncc = 0.8 #NCC threhold value. Values smaller than thresh_ncc are neglected
            win_size_ncc = 25 #win_size_ncc x win_size_ncc, window size for examining ssd metric

            Cord_NCC = NCC_metric(img1_gray,img2_gray,corner_img1,corner_img2,win_size_ncc,thresh_ncc)
            out_image_NCC = displayImagewithInterestPoints(img1,img2,Cord_NCC)
            cv2.imwrite('HarrisNCCbalcony'+'_sigma_'+str(sigma)+'.jpg',out_image_NCC)









"""# SIFT"""

!pip install opencv-python==3.4.2.16
!pip install opencv-contrib-python==3.4.2.16

import numpy as np
import cv2
import matplotlib.pyplot as plt

#get input images 
def get_input_images(n):
  if n==1:
    image1 = cv2.imread('/content/drive/My Drive/hw4_Task1_Images/pair1/1.JPG')
    image2 = cv2.imread('/content/drive/My Drive/hw4_Task1_Images/pair1/2.JPG')
  if n==2:
    image1 = cv2.imread('/content/drive/My Drive/hw4_Task1_Images/pair2/1.JPG')
    image2 = cv2.imread('/content/drive/My Drive/hw4_Task1_Images/pair2/2.JPG')
  if n==3:
    image1 = cv2.imread('/content/drive/My Drive/hw4_Task1_Images/pair3/1.jpg')
    image2 = cv2.imread('/content/drive/My Drive/hw4_Task1_Images/pair3/2.jpg')
  
  if n==4:
    image1 = cv2.imread('/content/drive/My Drive/hw4_Task1_Images/My_image1/1.jpg')
    image2 = cv2.imread('/content/drive/My Drive/hw4_Task1_Images/My_image1/2.jpg')
  if n==5:
    image1 = cv2.imread('/content/drive/My Drive/hw4_Task1_Images/my_image2/1.jpg')
    image2 = cv2.imread('/content/drive/My Drive/hw4_Task1_Images/my_image2/2.jpg')
  image1=cv2.cvtColor(image1,cv2.COLOR_BGR2RGB)
  image2=cv2.cvtColor(image2,cv2.COLOR_BGR2RGB)
  im1=image1.copy()
  im2=image2.copy()
  im1=cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)
  im2=cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY)

  plt.figure(figsize=(10,10))
  plt.imshow(im1,cmap='gray')
  plt.figure(figsize=(10,10))
  plt.imshow(im2,cmap='gray')
  return im1,im2,image1,image2

#get the SIFT keypoints
def get_SIFT_keypoints(im1,im2,n):
  sift = cv2.xfeatures2d.SIFT_create(nfeatures=1000,sigma=1.4)#nOctaveLayers=5,contrastThreshold=0.1,edgeThreshold=10,sigma=1.4)
  '''
  nfeatures= number of features to retain. 
  nOctaveLayers=	The number of layers in each octave. 
  contrastThreshold= The contrast threshold used to filter out weak features in semi-uniform (low-contrast)
  regions. The larger the threshold, the less features are produced by the detector.
  edgeThreshold=	The threshold used to filter out edge-like features. More the threshold, more edges preserved
  sigma= smoothening factor of Gaussian filter
  '''

  # find the keypoints and descriptors with SIFT
  keypoints_sift1, descriptors1 = sift.detectAndCompute(im1, None)
  keypoints_sift2, descriptors2 = sift.detectAndCompute(im2, None)
  
  img = cv2.drawKeypoints(im1, keypoints_sift1, None)
  img = cv2.cvtColor(img,cv2.COLOR_RGB2BGR)
  cv2.imwrite("kp"+str(n)+"1.JPG",img)
  img = cv2.drawKeypoints(im2, keypoints_sift2, None)
  img = cv2.cvtColor(img,cv2.COLOR_RGB2BGR)
  cv2.imwrite("kp"+str(n)+"2.JPG",img)
  return keypoints_sift1,descriptors1,keypoints_sift2,descriptors2

#get the matching points using BFMatcher 
def get_match_points(image1,image2,descriptors1,descriptors2,keypoints_sift1,keypoints_sift2,q):
  # BFMatcher with default params
  bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)
  matches = bf.match(descriptors1, descriptors2)
  good = sorted(matches, key=lambda x: x.distance)
  img3=cv2.drawMatches(image1,keypoints_sift1,image2,keypoints_sift2,good[0:20],None,flags=2)
  plt.figure(figsize=(40,40))
  plt.imshow(img3)
  img3 = cv2.cvtColor(img3,cv2.COLOR_RGB2BGR)
  cv2.imwrite("match"+str(q)+".JPG",img3)

## SIFT and Brute Force Syntax taken from https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_matcher/py_matcher.html
def SIFT(image1,image2,n):
  kp1,des1,kp2,des2 = get_SIFT_keypoints(image1,image2,n)
  get_match_points(image1,image2,des1,des2,kp1,kp2,n)

#image pair 1
im1,im2,image1,image2 = get_input_images(1)
SIFT(image1,image2,1)

#image2
im1,im2,image1,image2 = get_input_images(2)
SIFT(image1,image2,2)

#image 3
im1,im2,image1,image2 = get_input_images(3)
SIFT(image1,image2,3)

#my image 1
im1,im2,image1,image2 = get_input_images(4)
SIFT(image1,image2,4)

#my image 2
im1,im2,image1,image2 = get_input_images(5)
SIFT(image1,image2,5)